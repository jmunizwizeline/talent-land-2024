{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1 - Importamos dependencias necesarias para la demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el fichero **requirements.txt** están definidas las dependencias necesarias de Python para poder correr la demo.\n",
    "\n",
    "Para importarlas debemos ejecutar el siguiente comando: *pip install -r requirements.txt*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2 - Definimos las variables de entorno necesarias para la demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editar el fichero _.env_ donde debemos definir las siguientes variables de entorno:\n",
    "-  **OPENAI_API_KEY**: API Key para poder conectarnos al LLM que usaremos en la demo, OpenAI.\n",
    "-  **NEO4J_CONNECTION_URL**: URL de conexión a Neo4j, la base de datos orientada a grafos que usaremos en la demo.\n",
    "-  **NEO4J_USER**: Usuario para conectarnos a la bbdd.\n",
    "-  **NEO4J_PASSWORD**: Password para conectarnos a la bbdd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3 - Importar librerías de Python que necesitamos para la demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "# Load environment variables defined in .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 4 - Preparar el dataset para la demo \n",
    "\n",
    "Utilizaremos de base un dataset público que ha publicado MANISH KUMAR en Kaggle con un conjunto de datos de perfiles profesionales de Linkedin: https://www.kaggle.com/datasets/manishkumar7432698/linkedinuserprofiles?select=LinkedIn+people+profiles+datasets.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original .csv from Kaggle\n",
    "df = pd.read_csv('files/LinkedIn people profiles datasets.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpiaremos el dataset para quedarnos con los datos que necesitamos para nuestro knoledge graph:\n",
    "-  id: identificador único de profesional.\n",
    "-  name: nombre del profesional.\n",
    "-  company: nombre de la compañía en la que trabaja.\n",
    "-  education: institución educativa en la que se ha formado.\n",
    "-  languages: idiomas que habla.\n",
    "-  industry: industra principal en la que tiene experiencia.\n",
    "-  country: nacionalidad del trabajador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will fill the empty data with this random values (just for demo purposes)\n",
    "industries = ['Advertising Services', 'IT Services and IT Consulting', 'Hospitals and Health Care', 'Higher Education', 'Retail', 'Financial Services', 'Telco', 'Media & Entertainment']\n",
    "countries= ['United States', 'Argentina', 'Spain', 'France', 'Mexico', 'United Kingdom', 'Sweden']\n",
    "\n",
    "# Function to extract the industry from the company information\n",
    "def extract_industry(json_str):\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        return data.get('industry', random.choice(industries))\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "# Function to extract the languages from the languages structure\n",
    "def extract_languages(json_list):\n",
    "    try:\n",
    "        languages = [entry['title'] for entry in json.loads(json_list)]\n",
    "        return '|'.join(languages)\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "# Function to extract the country from the city structure\n",
    "def extract_country(string):\n",
    "    if isinstance(string, str):\n",
    "        elements = string.split(',')\n",
    "        return elements[-1].strip()  \n",
    "    else:\n",
    "        return random.choice(countries)\n",
    "\n",
    "# Extract the industry, languages and country information\n",
    "df['industry'] = df['current_company'].apply(lambda x: extract_industry(x))\n",
    "df['languages'] = df['languages'].apply(lambda x: extract_languages(x))\n",
    "df['country'] = df['city'].apply(lambda x: extract_country(x))\n",
    "\n",
    "# Remove the rows with empty values in these key columns (just for demo purposes)\n",
    "df = df [['id','name','current_company:name','educations_details','languages','industry','country']].dropna()\n",
    "\n",
    "# Rename some columns for better readability\n",
    "df = df.rename(columns={'current_company:name': 'company','educations_details':'education'})\n",
    "\n",
    "# Preview the curated data\n",
    "df.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: With this sentence you can save the curated csv in a new file called 'clean_data.csv'\n",
    "df.to_csv('files/clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 5 - Insertar los datos en Neo4J\n",
    "\n",
    "Lo primero será preparar el contector a Neo4j usando la utilidad Neo4jGraph de Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve connection information to Neo4j from environment variables\n",
    "neo4j_url = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USER\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/graphs/langchain_community.graphs.neo4j_graph.Neo4jGraph.html\n",
    "graph = Neo4jGraph(neo4j_url,neo4j_user,neo4j_password)\n",
    "\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos cargando la información que hemos preparado anteriormente en Neo4J con la utilidad de Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up the Cypher query to load the information from the csv that we have published on github\n",
    "people_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'https://raw.githubusercontent.com/jmunizwizeline/talent-land-2024/main/files/clean_data.csv'\n",
    "AS row\n",
    "MERGE (person:Person {name: row.name})\n",
    "MERGE (company:Company {name: row.company})\n",
    "MERGE (school:School {name: row.education})\n",
    "MERGE (industry:Industry {name: row.industry})\n",
    "MERGE (country:Country {name: row.country})\n",
    "\n",
    "FOREACH (lang in split(row.languages, '|') | \n",
    "    MERGE (language:Language {name:trim(lang)})\n",
    "    MERGE (person)-[:SPEAKS]->(language))\n",
    "\n",
    "MERGE (person)-[:WORKS_IN]->(company)\n",
    "MERGE (person)-[:LIVES_IN]->(country)\n",
    "MERGE (person)-[:EDUCATED_AT]->(school)\n",
    "MERGE (company)-[:IS_IN]->(industry)\n",
    "\"\"\"\n",
    "\n",
    "graph.query(people_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, confiramos que el esquema que tenemos en la base de datos se ha modificado y exploramos las relaciones que ha creado por nosotros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We confirm that the schematic has been loaded\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6 - Realizamos nuestra primera consulta sobre nuestro Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la utilidad ChatOpenAI que nos proporciona Langchain para conectarnos al API de OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2)\n",
    "\n",
    "# Langchain nos facilita este tipo de utilidades que permiten hacer Q&A a Neo4J usando como llm la instancia de ChatOpenAI que hemos creado anteriormente\n",
    "chain = GraphCypherQAChain.from_llm(graph=graph, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of questions that we want to run against the Knowledge Graph\n",
    "questions = [\"List all companies in Advertising Services industry!\",\n",
    "             \"A worker who graduated from Simon Fraser University what is his name?\",\n",
    "             \"Where is Paul Lukes working?\",\n",
    "             \"A worker residing in Canada who is proficient in Vietnamese?\",\n",
    "             \"How many workers from the United States speak Urdu?\",\n",
    "             \"How many workers work for Capgemini?\"]\n",
    "for q in questions:\n",
    "    print('====== START ======')\n",
    "    print(chain.invoke(q)['result'])\n",
    "    print('====== END ====== \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 7 - Mejorar la estrategia de prompting usando Rol Prompting y Few-Shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define some examples to show the model more details of the domain's structure\n",
    "examples= [\n",
    "    {\n",
    "        \"question\": \"Which workers speak French?\",\n",
    "        \"query\": \"MATCH (p:Person)-[:SPEAKS]->(l:Language {{name: 'French'}}) RETURN p.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What industries are workers named Emily associated with?\",\n",
    "        \"query\": \"MATCH (p:Person {{name: 'Emily'}})-[:WORKS_IN]->(c:Company)-[:IS_IN]->(i:Industry) RETURN i.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which workers live in Canada and speak German?\",\n",
    "        \"query\": \"MATCH (p:Person)-[:LIVES_IN]->(:Country {{name: 'Canada'}}), (p)-[:SPEAKS]->(:Language {{name: 'German'}}) RETURN p.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In which countries do workers who speak Spanish live?\",\n",
    "        \"query\": \"MATCH (p:Person)-[:SPEAKS]->(:Language {{name: 'Spanish'}})<-[:SPEAKS]-(worker:Person)-[:LIVES_IN]->(c:Country) RETURN DISTINCT c.name AS Country\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What companies do workers named John work in?\",\n",
    "        \"query\": \"MATCH (p:Person {{name: 'John'}})-[:WORKS_IN]->(c:Company) RETURN c.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\":\"How many workers in Hospital and Health Care industry able to speak Korea\",\n",
    "        \"query\": \"MATCH (p:Person)-[:WORKS_IN]->(:Company)-[:IS_IN]->(:Industry {{name: 'Hospitals and Health Care'}}),(p)-[:SPEAKS]->(:Language {{name: 'Korean'}}) RETURN COUNT(DISTINCT p) AS NumberOfWorkers\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What companies are located in the technology industry?\",\n",
    "        \"query\": \"MATCH (c:Company)-[:IS_IN]->(:Industry {{name: 'Technology'}}) RETURN c.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where do workers named Alice live?\",\n",
    "        \"query\": \"MATCH (p:Person {{name: 'Alice'}})-[:LIVES_IN]->(c:Country) RETURN c.name\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# We use another Langchain utility to implement the few-shot and prompting improvements\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"User input: {question}\\nCypher query: {query}\"\n",
    ")\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples[:3],\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"You are a Neo4j expert. Given an input question, create a syntactically correct Cypher query to run.\\n\\nHere is the schema information\\n{schema}.\\n\\nBelow are a number of examples of questions and their corresponding Cypher queries.\",\n",
    "    suffix=\"User input: {question}\\nCypher query: \",\n",
    "    input_variables=[\"question\", \"schema\"],\n",
    ")\n",
    "\n",
    "# We create a new connector with the new strategy that we have just created\n",
    "chain2 = GraphCypherQAChain.from_llm(graph=graph, llm=llm, cypher_prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of the prompt that we will run when we make a question\n",
    "print(prompt.format(question=\"Where do Michael work?\", schema=\"foo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run again the questions with this new improved strategy\n",
    "questions = [\"List all companies in Advertising Services industry!\",\n",
    "             \"A worker who graduated from Simon Fraser University what is his name?\",\n",
    "             \"Where is Paul Lukes working?\",\n",
    "             \"A worker residing in Canada who is proficient in Vietnamese?\",\n",
    "             \"How many workers from the United States speak Urdu?\",\n",
    "             \"How many workers work for Capgemini?\"]\n",
    "for q in questions:\n",
    "    print('====== START ======')\n",
    "    chain2.invoke(q)\n",
    "    print('====== END ====== \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 8 - Mejorar la calidad de los ejemplos que le pasamos al modelo usando similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# We use yet another Langchain utility to \n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    HuggingFaceEmbeddings(),\n",
    "    Neo4jVector,\n",
    "    url = neo4j_url,\n",
    "    username = neo4j_user,\n",
    "    password = neo4j_password,\n",
    "    k=4,\n",
    "    input_keys=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can see that the set of 3 examples that we have selected are better and also are sort\n",
    "example_selector.select_examples({\"question\": \"Where do Michael live?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the example selector and get rid of the examples=examples[:3]\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"You are a Neo4j expert. Given an input question, create a syntactically correct Cypher query to run.\\n\\nHere is the schema information\\n{schema}.\\n\\nBelow are a number of examples of questions and their corresponding Cypher queries.\",\n",
    "    suffix=\"User input: {question}\\nCypher query: \",\n",
    "    input_variables=[\"question\", \"schema\"],\n",
    ")\n",
    "\n",
    "# We create a new connector with the new strategy that we have just created\n",
    "chain3 = GraphCypherQAChain.from_llm(graph=graph, cypher_prompt=dynamic_prompt, llm=llm, verbose=True, top_k=32, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run again the questions with this new improved strategy\n",
    "questions = questions = [\"List all companies in Advertising Services industry!\",\n",
    "             \"A worker who graduated from Simon Fraser University what is his name?\",\n",
    "             \"Where is Paul Lukes working?\",\n",
    "             \"A worker residing in Canada who is proficient in Vietnamese?\",\n",
    "             \"How many workers from the United States speak Urdu?\",\n",
    "             \"How many workers work for Capgemini?\"]\n",
    "\n",
    "for q in questions:\n",
    "    print('====== START ======')\n",
    "    chain3.invoke(q)\n",
    "    print('====== END ====== \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
