{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Track - Ejemplo de uso de RAGAs para evaluar calidad de soluciones de IA Generativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1 - Importamos dependencias necesarias para la demo\n",
    "\n",
    "En el fichero **requirements.txt** están definidas las dependencias necesarias de Python para poder correr la demo.\n",
    "\n",
    "Para importarlas debemos ejecutar el siguiente comando: *pip install -r requirements.txt*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2 - Definimos las variables de entorno necesarias para la demo\n",
    "\n",
    "Editar el fichero _.env_ donde debemos definir las siguientes variables de entorno:\n",
    "-  **OPENAI_API_KEY**: API Key para poder conectarnos al LLM que usaremos en la demo, OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3 - Importar librerías de Python que necesitamos para la demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables defined in .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 4 - Cargamos un dataset de pruebas de HuggingFaces (explodinggradients/fiqa)\n",
    "\n",
    "For this tutorial we are going to use an example dataset from one of the baselines we created for the Financial Opinion Mining and Question Answering (fiqa) Dataset. The dataset has the following columns.\n",
    "\n",
    "-  question: list[str] - These are the questions your RAG pipeline will be evaluated on.\n",
    "-  answer: list[str] - The answer generated from the RAG pipeline and given to the user.\n",
    "-  contexts: list[list[str]] - The contexts which were passed into the LLM to answer the question.\n",
    "-  ground_truths: list[list[str]] - The ground truth answer to the questions. (only required if you are using context_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and we will only work on the first 10 questions\n",
    "fiqa_eval = load_dataset(\"explodinggradients/fiqa\", \"ragas_eval\")\n",
    "fiqa_eval_5_questions = fiqa_eval[\"baseline\"].select(range(5))\n",
    "\n",
    "# Show the dataset definition in terms of features and rows\n",
    "print(fiqa_eval_5_questions)\n",
    "\n",
    "# Show the dataset content\n",
    "for item in fiqa_eval_5_questions:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 5 - Primera prueba de RAG para el modelo GPT3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the ChatOpenAI Langchain utility to interact with the model\n",
    "chat_gpt_3_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2)\n",
    "\n",
    "# Invoque ChatGPT 3.5 with the dataset questions to get the answer for each of it\n",
    "answers = []\n",
    "for item in fiqa_eval_5_questions:\n",
    "    model_answer = chat_gpt_3_llm.invoke(item['question']).content\n",
    "    answers.append(model_answer)\n",
    "\n",
    "print(answers)\n",
    "\n",
    "# Prepare a dataset to evaluate with RAGAs with the questions and answers\n",
    "ragas_dataset = Dataset.from_dict({\n",
    "    'question': fiqa_eval_5_questions['question'],\n",
    "    'answer': answers,\n",
    "    'contexts': fiqa_eval_5_questions['contexts'],\n",
    "    'ground_truths': fiqa_eval_5_questions['ground_truths']\n",
    "})\n",
    "\n",
    "# Evaluate the results with RAGAs\n",
    "result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print them\n",
    "df = result.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6 - Mismo ejercico pero con ChatGPT 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the ChatOpenAI Langchain utility to interact with the model\n",
    "chat_gpt_4o_llm = ChatOpenAI(model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2)\n",
    "\n",
    "# Invoque ChatGPT 4o with the dataset questions to get the answer for each of it\n",
    "answers = []\n",
    "for item in fiqa_eval_5_questions:\n",
    "    model_answer = chat_gpt_4o_llm.invoke(item['question']).content\n",
    "    answers.append(model_answer)\n",
    "\n",
    "# Prepare a dataset to evaluate with RAGAs with the questions and answers\n",
    "ragas_dataset = Dataset.from_dict({\n",
    "    'question': fiqa_eval_5_questions['question'],\n",
    "    'answer': answers,\n",
    "    'contexts': fiqa_eval_5_questions['contexts'],\n",
    "    'ground_truths': fiqa_eval_5_questions['ground_truths']\n",
    "})\n",
    "\n",
    "# Evaluate the results with RAGAs\n",
    "result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print them\n",
    "df = result.to_pandas()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
